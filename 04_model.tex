%!TEX root = 00_main.tex

\input{figs/fig_model_suite.tex}

\section{Our Dynamic Eye-Region Model}

\input{figs/fig_process.tex}

We developed a realistic dynamic eye-region model which can be randomly posed to generate fully labeled training images.
% For a set of training images to be useful, it should be large, representitive of real-world variety, and cleanly labelled.
For training data to be useful, it should be representitive of real-world variety.
Our goal therefore was to model the continuous changes in appearance that the face and eyes undergo following eye movement, so they are accurately represented in close-up synthetic eye images.
This is more challenging than simply rendering a collection of static models, as dynamic geometry must be correctly topologized and rigged to be able to deform continuously.
% this sentence is a bit clunky
Appearance-wise, the eye-region is one of the most complex areas of the whole body. The eyelids, upper-cheek, and eye-ball can all move independently, and feature a range of reflectance properties and small-scale details.
%
In this section we first present our anatomically inspired computer graphics eyeball model, and then explain our procedure for converting a collection of static 3D head scans into dynamic eye-region models that can adopt a wide range of realistic poses, and are suitable for labelled data generation.
%\commentA{I think it would be good to first describe in 1-2 paragraphs what the particular challenges of modelling eye shape, dynamics etc. are. This gives better context for the method description that follows and hopefully also underlines that this is a non-trivial task and the work therefore a significant step forward.}

%\todo{past tense}
%\commentA{we have to explain what makes the model dynamic}
%\commentA{could be nice to show existing renderings and ours side by side, e.g. Leszeks and others (if any)}


\subsection{Simplified Eyeball Model}
\label{subsec:eyeball_model}

\begin{figure}
    \captionsetup[subfigure]{labelformat=empty} % stop subcaption writing "(a)""
    \captionsetup{subrefformat=parens} % add parentheses to \subref
    \begin{subfigure}[t]{0.33\columnwidth}
        \inlinelabel{a}{\includegraphics[width=\textwidth]{eye_model}}
        \caption{}\label{fig:eye_model_parts}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.65\columnwidth}
        \inlinelabel{b}{\includegraphics[width=\textwidth]{eye_examples}}
        \caption{}\label{fig:eye_model_images}
    \end{subfigure}
    \par\vspace{-28pt}
    \caption{Our eye model includes the sclera, pupil, iris, and cornea \subref{fig:eye_model_parts} and can exhibit realistic variation in both shape (pupillary dilation) and texture (iris color, scleral veins) \subref{fig:eye_model_images}.}
    \label{fig:eye_model}
\end{figure}

% It is important to accurately model reflections and refractions in the eye as they can lead to specular highlights -- these common eye-region image features are often used by eye-tracking algorithms, or can confound approaches that are not robust.

As shown in \autoref{fig:eye_model_parts}, our eye model consists of two parts.
The outer part (red wireframe) approximates the eye's overall shape with two spheres ($r_1\!=\!12\textrm{mm}, r_2\!=\!8\textrm{mm}$ \cite{ruhland2014look}), the latter representing the corneal bulge.
To avoid a discontinuous seam between spheres, their meshes were joined, and the vertices along the seam where smoothed to minimize differences in face-angle.
% \commentA{how joined and smoothed?} Erroll - Maybe needs rewording. Perhaps i'll just put a citation for the smoothing operation? I don't particularly want to describe it
This outer part is transparent, refractive ($n\!=\!1.376$), and partially reflective.
The sclera's bumpy surface is modelled with smoothed solid noise functions, and applied using a \emph{displacement map} -- a 2D scalar function that shifts a surface in the direction of its normal \cite{lee2000displaced}.
The inner part (blue wireframe) is a flattened sphere  -- the planar end represents the iris and pupil, and the rest represents the sclera, the white of the eye.
There is a $0.5\textrm{mm}$ gap between the two parts which accounts for the thickness of the cornea.
% \commentE{compare with recent Disney work}

Eyes exhibit variation in both shape (pupillary dilation) and texture (iris color and scleral veins).
To model shape variation we use \emph{blend shapes} -- an animation technique where several different poses are created for the same topological mesh, and then interpolated between\cite{orvalho2012facial}. 
We created blend shapes for dilated and constricted pupils, as well as large and small irises to account for a small amount ($10\%$) of variation in iris size.
% Maybe try to explain blend shapes better
% Blend shapes are localized so can be mixed, so we can easily model an eye with a small pupil, and a large iris.
We vary the texture of the eye by randomly compositing images in three separate layers:
\begin{inparaenum}[\itshape i\upshape)]
\item a \emph{sclera} tint layer (white, pink, or yellow);
\item an \emph{iris} layer with four different photo-textures (amber, blue, brown, grey); and
\item a \emph{veins} layer (blood-shot or clear).
\end{inparaenum}
% We matched the sclera tint to each separate face model but uniformably randomly varied iris color.
% Maybe move to related work?
% Previous research on iris-synthesis \commentE{cite} would have allowed continually different iris textures, but we decided this added complexity would not make a worthwhile improvement in overall appearance variation, especially when rendered at lower resolutions.

\subsection{3D Head Scan Acquisition}
\label{sec:eye_region_geom_prep}

For an eye-region rendering to be realistic, it must also feature realistic nearby face detail.
While previous approaches used lifelike artist-created models, for example~\cite{swirski2014rendering}, we instead rely on high-quality head scans captured by a professional photogrammetry studio (10K diffuse color textures, 0.1mm resolution geometry)\footnote{Ten24 3D Scan Store -- \url{http://www.3dscanstore.com/}}.
%\cite{Ten24}.
%\commentA{link or even better reference if available}
%Nowadays it is possible to purchase such scans online (from $\sim\!\$15$/scan)
%or use free or commercial photogrammetry software to generate facial geometry models in-house.
Facial appearance around the eye varies dramatically between people as a result of different eye-shapes (e.g. round vs hooded), orbital bone structure (e.g. deep-set vs protruding), and flesh detail (wrinkled vs flat). Therefore our head models (see \autoref{fig:model_suite}) cover both genders with a variety of ethnicities and ages.

\subsection{Eye-Region Geometry Preparation}

As can be seen in \autoref{fig:process_original_scan}, the cornea has been incorrectly reconstructed by the optical scanning process.
This is because transparent surfaces are not directly visible, so cannot be reconstructed in the same way as diffuse surfaces, such as skin.
Recent work used a hybrid reconstruction method to reconstruct the corneal surface separately, but requires additional hardware \cite{berard2014highquality} -- this level of detail was deemed unnecessary for our purposes.
We wanted images representing a wide range of eye-gaze directions, so we needed to be able to pose the eyeball separately from the face geometry.
We therefore removed the scanned eyeball from the mesh, and placed our own eyeball approximation in its place.

While the original head scan geometry is suitable for being rendered as a static model, its topology cannot easily represent dynamic changes in eye-region shape.
Vertical saccades are always accompanied by eyelid motion \cite{liversedge2011oxford}, so we needed to be able to pose the eyelids according to the gaze vector.
When preparing a mesh for facial animation, edge loops should flow along and around the natural contours of facial muscles.
This leads to a more efficient (low-resolution) geometric representation of the face, and more realistic animation as mesh deformation matches that of actual skin tissue and muscles.

% Maybe: \commentE{Reference some other options, e.g automatic methods in research}

We therefore \emph{retopologized} the face geometry into a more optimal form using a commercial semi-automatic system \cite{ZRemesher}.
% Erroll: changed just the sentence below to present tense. As the model still exists, perhaps the tense should be present? Not sure.
As can be seen in \autoref{fig:process_retopo}, edge loops now follow the \emph{Orbicularis Oculi} muscle, allowing for realistic eye-region deformations.
This retopologized low-poly mesh has now lost the detail of the original scan and has visible sharp edges.
We therefore used it as a displaced subdivision surface \cite{lee2000displaced} with displacement map computed from the scanned geometry, thus restoring skin surface detail like wrinkles and creases (see \autoref{fig:process_displaced_subdiv}).
Although they are two separate organs, there is normally no visible gap between eyeball and skin.
However, as a consequence of removing the eyeball from the original scan, the retopologized mesh will not necessarily meet the eyeball geometry (see \autoref{fig:process_retopo}).
To compensate for this, the face mesh's eyelid vertices are automatically displaced along their normals to their respective closest positions on the eyeball geometry (see \autoref{fig:process_displaced_subdiv}) \cite{Shrinkwrap}.
This prevents unwanted gaps between the models, even after changes in pose.
The face geometry is then assigned physically-based materials, including subsurface scattering to approximate the penetrative light transfer properties of skin, and a glossy component to simulate its oily surface.


\subsection{Modelling Eyelid Motion}

\commentA{just as a reminder for later: we might want to use this as a minor method contribution if it is really novel and key to performance improvements (remains to be seen)}

When someone looks up or down, their eyelids move accordingly \cite{liversedge2011oxford}.
To simulate this we created blend shapes for upwards-looking and downwards-looking eyelids, and interpolate between them based on the global pitch of the eyeball model.
This makes our face-model dynamic, allowing it to continuously deform to match eyeball poses.
Rather than rendering a single or perhaps several discrete head scans representing a particular gaze vector, for example \cite{sugano2014learning}, we can instead create training data with a dense distribution of facial deformation.
Defining blend shapes through vertex manipulation can be a difficult and time-consuming task but fortunately, only two are required and they have small regions of support.
As the tissue around the eye is compressed or stretched, skin details like wrinkles and folds are either attenuated or exaggerated (see \autoref{fig:eyelids}).
% As shown in \autoref{fig:eyelids}, downwards-looking eyelids appear smooth compared with the folds in an upwards-looking eyelid.
We modeled this by using smoothed color and displacement textures for downwards-looking eyelids, removing any wrinkles.
These blend shape and texture modifications were carried out using photos of the same heads looking up and down as references.
However, an alternative would be to purchase the corresponding head scans and match the blend shape to that geometry.

\begin{figure}
    \includegraphics[width=\columnwidth]{eyelid_motion.png}
    \caption{Eyelids are posed by interpolating between blend shapes based on gaze direction. Note how we simulate the folding of the skin above and below the eye.}
    \label{fig:eyelids}
\end{figure}

% Eyelashes are connected to eyelids after all, so I think we can join subsections here.
% \subsection{Modelling of Eyelashes}

Eyelashes are short curved hairs that grow from the edges of the eyelids.
These can occlude parts of the eye and affect eye tracking algorithms, so are simulated as part of our comprehensive model.
We followed the approach of \citet{swirski2014rendering}, and model eyelashes using directed hair particle effects.
The particles were generated from a control surface manually placed below the eyelids.
To make them curl, eyelash particles experience a slight amount of gravity during growth (negative gravity for the upper eyelash).

\subsection{Eye-Region Landmark Annotation}

As shown in \autoref{fig:process_ldmks}, each 3D eye-region was annotated once in 3D with $28$ landmarks, corresponding to the eye corners ($2$), eyelids ($5\!+\!5$), iris boundary ($8$), and pupil boundary ($8$).
The iris and pupil landmarks were defined as a subset of the eyeball geometry vertices, so deform automatically with changes in pupil and iris size.
The eyelid and eye corner landmarks were manually labelled with a separate mesh that follows the seam where eyeball geometry meets skin geometry.
This mesh is assigned shape keys and deforms automatically during eyelid motion.
%
% So instead of having humans ambiguously label eye-region anatomy, we carefully manually annotate each eye-region once, ensuring higher-quality labels.
% Maybe put the sentence below in later
Whenever an image is rendered, the 2D image-space coordinates of these 3D landmarks are calculated using the camera projection matrix and saved.